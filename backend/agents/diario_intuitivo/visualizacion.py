"""
Herramienta para generar visualizaciones del r√≠o emocional
"""
import io
import os
from datetime import datetime
from pathlib import Path as FilePath
from PIL import Image, ImageDraw, ImageFont
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib.path import Path
import numpy as np
import google.genai.types as types

# Mapeo de emojis a colores emocionales
EMOJI_COLORES = {
    # Alegr√≠a y positividad
    'üòä': '#FFD700', 'üòÉ': '#FFA500', 'üòÑ': '#FFB347', 'ü•∞': '#FF69B4',
    'üòç': '#FF1493', 'ü§ó': '#FF6B9D', 'üòÅ': '#FFDB58', 'üåü': '#FFD700',
    '‚ú®': '#E6E6FA', 'üíñ': '#FF69B4', 'üíï': '#FFB6C1', '‚ù§Ô∏è': '#DC143C',
    'üå∏': '#FFB7C5', 'üå∫': '#FF6B9D', 'üåº': '#FFDB58',

    # Calma y serenidad
    'üòå': '#87CEEB', 'üòá': '#B0E0E6', 'üåä': '#4682B4', 'üíô': '#1E90FF',
    'üíö': '#3CB371', 'üåø': '#90EE90', 'üçÉ': '#98FB98', 'üå±': '#32CD32',
    '‚òÅÔ∏è': '#E0E0E0', 'üåô': '#F0E68C', '‚≠ê': '#FFFACD',

    # Tristeza y melancol√≠a
    'üò¢': '#4169E1', 'üò≠': '#0000CD', 'üòî': '#6495ED', 'üíî': '#8B0000',
    'üåßÔ∏è': '#778899', '‚òî': '#696969', 'üíß': '#ADD8E6',

    # Energ√≠a y pasi√≥n
    'üî•': '#FF4500', '‚ö°': '#FFFF00', 'üí•': '#FF6347', 'üåã': '#DC143C',

    # Naturaleza y crecimiento
    'üå≥': '#228B22', 'üå≤': '#006400', 'üå¥': '#00FF00', 'ü™¥': '#3CB371',

    # Misterio y profundidad
    'üåë': '#2F4F4F', 'üñ§': '#000000', 'üíú': '#8B008B', 'üîÆ': '#9370DB',

    # Neutral
    'default': '#A9A9A9'
}

def obtener_color_emoji(emoji):
    """Obtiene el color asociado a un emoji"""
    return EMOJI_COLORES.get(emoji, EMOJI_COLORES['default'])

def generar_rio_emocional(emojis_texto: str) -> bytes:
    """
    Genera una visualizaci√≥n art√≠stica del r√≠o emocional

    Args:
        emojis_texto: String con los emojis separados por espacios

    Returns:
        bytes: Imagen PNG del r√≠o emocional
    """
    # Extraer emojis individuales
    emojis = emojis_texto.split()
    if not emojis:
        emojis = ['‚ùì']

    # Configurar la figura
    fig, ax = plt.subplots(figsize=(12, 8), facecolor='#F5F5F5')
    ax.set_xlim(0, 10)
    ax.set_ylim(0, 10)
    ax.axis('off')

    # T√≠tulo po√©tico
    ax.text(5, 9.5, 'El R√≠o de tu Pensamiento',
            fontsize=24, ha='center', va='top',
            weight='bold', color='#2C3E50')

    # Generar el flujo del r√≠o
    num_emojis = len(emojis)
    x_positions = np.linspace(1, 9, num_emojis)

    # Crear una onda sinusoidal para el r√≠o
    x_river = np.linspace(0, 10, 200)
    y_base = 5

    # Dibujar el r√≠o con colores que fluyen
    for i in range(len(emojis)):
        if i < len(emojis) - 1:
            x_start = x_positions[i]
            x_end = x_positions[i + 1]

            # Seleccionar puntos del r√≠o en este segmento
            mask = (x_river >= x_start) & (x_river <= x_end)
            x_segment = x_river[mask]

            # Crear ondas suaves
            y_wave = y_base + 0.3 * np.sin(2 * np.pi * x_segment / 2)

            # Color del segmento basado en el emoji
            color = obtener_color_emoji(emojis[i])

            # Dibujar el segmento del r√≠o con degradado
            for j in range(len(x_segment) - 1):
                alpha = 0.6 + 0.4 * (j / len(x_segment))
                ax.plot(x_segment[j:j+2], y_wave[j:j+2],
                       color=color, linewidth=15, alpha=alpha,
                       solid_capstyle='round')

    # Dibujar c√≠rculos con los emojis
    for i, (emoji, x_pos) in enumerate(zip(emojis, x_positions)):
        color = obtener_color_emoji(emoji)

        # Posici√≥n en la onda
        y_pos = y_base + 0.3 * np.sin(2 * np.pi * x_pos / 2)

        # C√≠rculo de fondo
        circle = plt.Circle((x_pos, y_pos), 0.4,
                           color=color, alpha=0.7, zorder=10)
        ax.add_patch(circle)

        # Emoji en el centro
        ax.text(x_pos, y_pos, emoji,
               fontsize=32, ha='center', va='center', zorder=11)

        # Peque√±a etiqueta con n√∫mero de secuencia
        ax.text(x_pos, y_pos - 0.7, f'{i+1}',
               fontsize=12, ha='center', va='top',
               color='#555', weight='bold')

    # Agregar texto po√©tico al final
    num_total = len(emojis)
    texto_po√©tico = f'Un camino de {num_total} {"paso" if num_total == 1 else "pasos"} emocionales'
    ax.text(5, 1.5, texto_po√©tico,
           fontsize=14, ha='center', va='center',
           style='italic', color='#555')

    # Agregar l√≠nea de horizonte sutil
    ax.axhline(y=10, color='#E0E0E0', linewidth=1, linestyle='--', alpha=0.5)
    ax.axhline(y=0, color='#E0E0E0', linewidth=1, linestyle='--', alpha=0.5)

    # Guardar en bytes
    buf = io.BytesIO()
    plt.tight_layout()
    plt.savefig(buf, format='png', dpi=150, bbox_inches='tight',
                facecolor='#F5F5F5')
    plt.close(fig)

    buf.seek(0)
    return buf.read()

async def crear_visualizacion(emojis: str) -> str:
    """
    Tool del agente para crear y guardar visualizaci√≥n del r√≠o emocional

    Args:
        emojis: String con los emojis a visualizar (ej: "üòä üåä üíö üåü")

    Returns:
        str: Mensaje de confirmaci√≥n
    """
    try:
        # Generar la visualizaci√≥n
        imagen_bytes = generar_rio_emocional(emojis)

        # Crear artifact
        artifact = types.Part.from_bytes(
            data=imagen_bytes,
            mime_type="image/png"
        )

        # Guardar (esto requiere context, se configurar√° en el agente)
        return f"‚ú® He creado una visualizaci√≥n de tu r√≠o emocional con los emojis: {emojis}"

    except Exception as e:
        return f"‚ö†Ô∏è Hubo un problema al crear la visualizaci√≥n: {str(e)}"

# ---- Aqu√≠ empez√≥ la prueba usando Numpy/Pillow ----

def interpretar_texto_a_parametros(texto: str) -> dict:
    """
    Interpreta un texto de manera abstracta y lo convierte en par√°metros matem√°ticos

    Args:
        texto: El texto a interpretar

    Returns:
        dict: Diccionario con par√°metros matem√°ticos interpretados
    """
    # An√°lisis b√°sico del texto
    longitud = len(texto)
    vocales = sum(1 for c in texto.lower() if c in 'aeiou√°√©√≠√≥√∫')
    consonantes = sum(1 for c in texto.lower() if c.isalpha() and c not in 'aeiou√°√©√≠√≥√∫')
    espacios = texto.count(' ')
    palabras = len(texto.split())

    # Calcular "intensidad emocional" basada en puntuaci√≥n
    signos_exclamacion = texto.count('!')
    signos_pregunta = texto.count('?')
    signos_puntos = texto.count('.')

    # Crear semilla √∫nica basada en el texto para reproducibilidad
    semilla = sum(ord(c) for c in texto) % 10000

    return {
        'longitud': longitud,
        'vocales': vocales,
        'consonantes': consonantes,
        'espacios': espacios,
        'palabras': palabras,
        'intensidad': signos_exclamacion * 1.5 + signos_pregunta * 0.8, # M√°s peso a exclamaci√≥n
        'calma': signos_puntos * 0.7, # M√°s puntos = m√°s calma
        'frecuencia_onda': max(0.5, vocales / 7),  # M√°s vocales = m√°s ondas base
        'amplitud_onda': max(0.1, consonantes / 15),  # M√°s consonantes = m√°s amplitud base
        'num_puntos': max(300, longitud * 15),  # M√°s texto = m√°s puntos totales para detalle
        'semilla': semilla,
        'signos_pregunta': signos_pregunta,
    }

def generar_puntos_numpy(parametros: dict, img_width: int, img_height: int) -> list:
    """
    Genera puntos usando NumPy bas√°ndose en los par√°metros interpretados,
    dividido en fases narrativas con l√≥gica ajustada a la emoci√≥n.

    Args:
        parametros: Diccionario con par√°metros matem√°ticos
        img_width (int): Ancho del canvas para l√≠mites.
        img_height (int): Alto del canvas para l√≠mites.

    Returns:
        list: Una lista de tuplas (x, y) con las coordenadas del trazo principal.
    """
    np.random.seed(parametros['semilla'])

    # Normalizar intensidad y calma para que est√©n en un rango manejable (0-1)
    max_intensidad = 10
    max_calma = 5

    norm_intensidad = np.clip(parametros['intensidad'] / max_intensidad, 0, 1)
    norm_calma = np.clip(parametros['calma'] / max_calma, 0, 1)

    # --- Configuraci√≥n global del trazo ---
    num_puntos_total = parametros['num_puntos']

    # Punto de inicio completamente aleatorio en el canvas, con variaci√≥n emocional
    start_x = np.random.randint(50, img_width - 50) + int(norm_intensidad * 50 - norm_calma * 20)
    start_y = np.random.randint(50, img_height - 50) + int(norm_calma * 50 - norm_intensidad * 20)
    current_x, current_y = start_x, start_y

    all_main_trace_points = [] # Puntos principales del trazo

    # --- Definici√≥n de Fases ---

    # Fase 1: Acelera con decisi√≥n
    num_puntos_fase1 = int(num_puntos_total * (0.25 + norm_intensidad * 0.1 - norm_calma * 0.05))
    num_puntos_fase1 = np.clip(num_puntos_fase1, 30, num_puntos_total // 2)

    avance_x1 = (2 + norm_intensidad * 3) * (1 - norm_calma * 0.5)
    avance_y1 = (-3 - norm_intensidad * 3) * (1 - norm_calma * 0.5)
    amplitud_onda1 = parametros['amplitud_onda'] * (1 - norm_intensidad * 0.7) + norm_calma * 15
    frecuencia_onda1 = parametros['frecuencia_onda'] * (1 + norm_intensidad * 0.8) * (1 - norm_calma * 0.4)
    ruido_aleatorio1 = (10 + norm_intensidad * 10) * (1 - norm_calma * 0.5)

    # Fase 2: Estallido de alegr√≠a
    num_puntos_fase2 = int(num_puntos_total * (0.35 + norm_intensidad * 0.2 - norm_calma * 0.1))
    num_puntos_fase2 = np.clip(num_puntos_fase2, 30, num_puntos_total // 2)

    avance_x2 = (1.5 + norm_intensidad * 2) * (1 - norm_calma * 0.3)
    avance_y2 = (-2.5 - norm_intensidad * 2) * (1 - norm_calma * 0.3)
    amplitud_onda2 = parametros['amplitud_onda'] * (1 - norm_intensidad * 0.3) + norm_calma * 30
    frecuencia_onda2 = parametros['frecuencia_onda'] * (1 + norm_intensidad * 1.5) * (1 - norm_calma * 0.2)
    ruido_aleatorio2 = (25 + norm_intensidad * 30) * (1 + (1 - norm_calma) * 0.5)

    # Fase 3: Se contrae con delicadeza
    num_puntos_fase3 = num_puntos_total - num_puntos_fase1 - num_puntos_fase2
    num_puntos_fase3 = max(10, num_puntos_fase3)

    avance_x3 = (0.5 + (1 - norm_calma) * 1.5) * (1 - norm_intensidad * 0.3)
    avance_y3 = (-0.5 - (1 - norm_calma) * 1.5) * (1 - norm_intensidad * 0.3)
    amplitud_onda3 = parametros['amplitud_onda'] * (1 - norm_intensidad * 0.9) + (1 - norm_calma) * 10
    frecuencia_onda3 = parametros['frecuencia_onda'] * (1 + (1 - norm_calma) * 2 + norm_intensidad * 0.5)
    ruido_aleatorio3 = (15 + (1 - norm_calma) * 20) * (1 + norm_intensidad * 0.5)

    # --- Generaci√≥n de Puntos por Fases ---
    phases_params = [
        (num_puntos_fase1, avance_x1, avance_y1, amplitud_onda1, frecuencia_onda1, ruido_aleatorio1),
        (num_puntos_fase2, avance_x2, avance_y2, amplitud_onda2, frecuencia_onda2, ruido_aleatorio2),
        (num_puntos_fase3, avance_x3, avance_y3, amplitud_onda3, frecuencia_onda3, ruido_aleatorio3),
    ]

    wave_offset = 0

    for i_phase, (n_puntos, av_x, av_y, amp_onda, freq_onda, ruido) in enumerate(phases_params):
        for i in range(n_puntos):
            random_freq_factor = (0.8 + np.random.rand() * 0.4)
            current_freq_x = freq_onda * 0.05 * random_freq_factor
            current_freq_y = freq_onda * 0.03 * random_freq_factor

            onda_x = amp_onda * np.sin((i + wave_offset) * current_freq_x)
            onda_y = amp_onda * np.cos((i + wave_offset) * current_freq_y)

            dx = av_x + np.random.normal(0, ruido / 10) + onda_x
            dy = av_y + np.random.normal(0, ruido / 10) + onda_y

            current_x += dx
            current_y += dy

            current_x = np.clip(current_x, 20, img_width - 20)
            current_y = np.clip(current_y, 20, img_height - 20)

            all_main_trace_points.append((int(current_x), int(current_y)))

        wave_offset += n_puntos

    return all_main_trace_points

def generar_imagen_texto(texto: str) -> Image.Image:
    """
    Genera una imagen interpretativa del texto usando Pillow,
    con el trazo dividido en fases narrativas y grosor din√°mico,
    y m√∫ltiples estilos de trazo.

    Args:
        texto: El texto a visualizar

    Returns:
        Image: Imagen PIL generada
    """
    # Interpretar el texto
    parametros = interpretar_texto_a_parametros(texto)

    # Crear canvas
    width, height = 1000, 700
    imagen = Image.new('RGB', (width, height), color='#F5F5F5')
    draw = ImageDraw.Draw(imagen)

    # Normalizar intensidad y calma para el grosor y estilo del trazo
    max_intensidad = 10
    max_calma = 5
    norm_intensidad = np.clip(parametros['intensidad'] / max_intensidad, 0, 1)
    norm_calma = np.clip(parametros['calma'] / max_calma, 0, 1)

    # Generar puntos del trazo principal
    main_trace_points = generar_puntos_numpy(parametros, width, height)

    # --- T√≠tulo ---
    titulo = "Trazo del Pensamiento"
    try:
        from PIL import ImageFont
        font_path = "arial.ttf"
        try:
            font = ImageFont.truetype(font_path, 24)
            font_small = ImageFont.truetype(font_path, 12)
        except IOError:
            font = ImageFont.load_default()
            font_small = ImageFont.load_default()
    except ImportError:
        font = ImageFont.load_default()
        font_small = ImageFont.load_default()

    draw.text((width // 2, 30), titulo, fill="#000000", anchor='mm', font=font)

    # --- Selecci√≥n de Estilo de Trazo y Dibujo ---
    if not main_trace_points or len(main_trace_points) < 2:
        print("No hay suficientes puntos para dibujar el trazo.")
        draw.text((width // 2, height // 2), "No se pudo generar el trazo", fill="#FF0000", anchor='mm', font=font)
        return imagen

    # L√≥gica de selecci√≥n de estilo de trazo
    if norm_intensidad > 0.8 and norm_calma < 0.2:
        # Estilo "Disperso" / "Nube de Puntos"
        print("Estilo de trazo: Disperso")
        for x, y in main_trace_points:
            num_dots = np.random.randint(5, 15)
            for _ in range(num_dots):
                dx = np.random.normal(0, 10 + norm_intensidad * 20)
                dy = np.random.normal(0, 10 + norm_intensidad * 20)
                dot_x, dot_y = int(x + dx), int(y + dy)
                draw.ellipse([dot_x-2, dot_y-2, dot_x+2, dot_y+2], fill="black", outline="black")

    elif norm_calma > 0.7 and norm_intensidad < 0.3:
        # Estilo "Solitario" / "Fino"
        print("Estilo de trazo: Solitario")
        base_width = 1
        color = (0, 0, 0, int(255 * (0.3 + norm_calma * 0.7)))

        temp_img = Image.new('RGBA', (width, height), (0,0,0,0))
        temp_draw = ImageDraw.Draw(temp_img)
        for i in range(len(main_trace_points) - 1):
            temp_draw.line([main_trace_points[i], main_trace_points[i + 1]], fill=color, width=base_width, joint="curve")
        imagen = Image.alpha_composite(imagen.convert('RGBA'), temp_img).convert('RGB')
        draw = ImageDraw.Draw(imagen)

    elif norm_intensidad > 0.5 and norm_calma > 0.4:
        # Estilo "S√≥lido" / "Marcado"
        print("Estilo de trazo: S√≥lido")
        dynamic_width = int(5 + norm_intensidad * 8 - norm_calma * 2)
        dynamic_width = max(2, dynamic_width)

        for i in range(len(main_trace_points) - 1):
            current_width = dynamic_width
            if i > len(main_trace_points) * 0.8 and norm_calma < 0.5:
                reduction_factor = (1 - (i - len(main_trace_points) * 0.8) / (len(main_trace_points) * 0.2))
                current_width = int(current_width * reduction_factor)
            draw.line([main_trace_points[i], main_trace_points[i + 1]], fill="black", width=max(1, current_width), joint="curve")

    elif norm_intensidad > 0.3 and norm_calma < 0.5 and parametros['signos_pregunta'] > 0:
        # Estilo "Fragmentado" / "Interrumpido"
        print("Estilo de trazo: Fragmentado")
        segment_length_base = 15 + norm_intensidad * 10
        gap_length_base = 5 + (1 - norm_calma) * 10

        i = 0
        while i < len(main_trace_points) - 1:
            segment_length = int(segment_length_base * (0.8 + np.random.rand() * 0.4))
            gap_length = int(gap_length_base * (0.8 + np.random.rand() * 0.4))

            end_segment = min(i + segment_length, len(main_trace_points) -1)
            if i < end_segment:
                draw.line(main_trace_points[i:end_segment+1], fill="black", width=2, joint="curve")

            i = end_segment + gap_length

    else:
        # Estilo "B√°sico Org√°nico"
        print("Estilo de trazo: B√°sico Org√°nico")
        base_width = 2
        dynamic_width_factor = 1 + norm_intensidad * 3 - norm_calma * 1.5

        for i in range(len(main_trace_points) - 1):
            current_width = int(base_width * dynamic_width_factor)
            if i > len(main_trace_points) * 0.7:
                 reduction_factor = (1 - (i - len(main_trace_points) * 0.7) / (len(main_trace_points) * 0.3))
                 current_width = int(current_width * reduction_factor * (1 + (1 - norm_calma) * 2))

            draw.line([main_trace_points[i], main_trace_points[i + 1]], fill="black", width=max(1, current_width), joint="curve")

    # Fecha y hora de creaci√≥n en la parte inferior
    fecha_hora = datetime.now().strftime("%d/%m/%Y - %H:%M:%S")
    draw.text((width // 2, height - 20), fecha_hora, fill='#555', anchor='mm', font=font_small)

    return imagen

def guardar_imagen_texto(texto: str) -> str:
    """
    Genera y guarda una imagen interpretativa del texto

    Args:
        texto: El texto a visualizar

    Returns:
        str: Ruta donde se guard√≥ la imagen
    """
    # Generar la imagen
    imagen = generar_imagen_texto(texto)

    # Crear nombre de archivo √∫nico
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    nombre_archivo = f"trazo_{timestamp}.png"

    # Determinar ruta de guardado
    proyecto_root = FilePath(__file__).parent.parent.parent
    carpeta_imagenes = proyecto_root / "imagenes_generadas"
    carpeta_imagenes.mkdir(exist_ok=True)

    ruta_completa = carpeta_imagenes / nombre_archivo

    # Guardar imagen
    imagen.save(ruta_completa, 'PNG')

    return str(ruta_completa)
